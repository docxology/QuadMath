\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Equations and Math Supplement (Appendix)}{1}{section.1}\protected@file@percent }
\newlabel{equations-and-math-supplement-appendix}{{1}{1}{Equations and Math Supplement (Appendix)}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Volume of a Tetrahedron (Lattice)}{1}{subsection.1.1}\protected@file@percent }
\newlabel{volume-of-a-tetrahedron-lattice}{{1.1}{1}{Volume of a Tetrahedron (Lattice)}{subsection.1.1}{}}
\newlabel{eq:supp_lattice_det}{{1}{1}{Volume of a Tetrahedron (Lattice)}{equation.1.1}{}}
\newlabel{eq:supp_ace5x5}{{2}{1}{Volume of a Tetrahedron (Lattice)}{equation.1.2}{}}
\newlabel{eq:supp_xyz_det}{{3}{2}{Volume of a Tetrahedron (Lattice)}{equation.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Fisher Information Matrix (FIM)}{2}{subsection.1.2}\protected@file@percent }
\newlabel{eq:fim}{{1.2}{2}{Fisher Information Matrix (FIM)}{subsection.1.2}{}}
\newlabel{eq:supp_fim}{{4}{2}{Fisher Information Matrix (FIM)}{equation.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Natural Gradient}{2}{subsection.1.3}\protected@file@percent }
\newlabel{eq:natgrad}{{1.3}{2}{Natural Gradient}{subsection.1.3}{}}
\newlabel{eq:supp_natgrad}{{5}{2}{Natural Gradient}{equation.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Free Energy (Active Inference)}{2}{subsection.1.4}\protected@file@percent }
\newlabel{eq:free_energy}{{1.4}{2}{Free Energy (Active Inference)}{subsection.1.4}{}}
\newlabel{eq:supp_free_energy}{{6}{2}{Free Energy (Active Inference)}{equation.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Figures}{3}{subsubsection.1.4.1}\protected@file@percent }
\newlabel{figures}{{1.4.1}{3}{Figures}{subsubsection.1.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Natural gradient trajectory demonstrating information-geometric optimization}. This trajectory shows natural gradient descent (Eq. \ref  {eq:supp_natgrad}) converging on a quadratic objective function. \textbf  {Trajectory}: The blue line with markers traces the parameter evolution from initial guess to final optimum, showing the path taken through the 2D parameter space. \textbf  {Markers}: Each marker represents one optimization step, with spacing indicating the step size and convergence rate. \textbf  {Convergence behavior}: The trajectory shows smooth, direct convergence to the optimum, characteristic of natural gradient descent on well-conditioned objectives. \textbf  {Comparison with standard gradient descent}: Natural gradient descent typically produces more direct trajectories than standard gradient descent, especially on ill-conditioned problems where the parameter space has strong anisotropy. This efficiency comes from the FIM-based scaling that adapts step sizes to local curvature. The trajectory demonstrates how information-geometric optimization leverages the intrinsic geometry of the parameter space to achieve faster, more stable convergence than naive gradient methods.}}{3}{figure.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Quadray Normalization (Fuller.4D)}{3}{subsection.1.5}\protected@file@percent }
\newlabel{quadray-normalization-fuller.4d}{{1.5}{3}{Quadray Normalization (Fuller.4D)}{subsection.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Distance (Embedding Sketch; Coxeter.4D slice)}{3}{subsection.1.6}\protected@file@percent }
\newlabel{distance-embedding-sketch-coxeter.4d-slice}{{1.6}{3}{Distance (Embedding Sketch; Coxeter.4D slice)}{subsection.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Minkowski Line Element (Einstein.4D analogy)}{3}{subsection.1.7}\protected@file@percent }
\newlabel{minkowski-line-element-einstein.4d-analogy}{{1.7}{3}{Minkowski Line Element (Einstein.4D analogy)}{subsection.1.7}{}}
\newlabel{eq:supp_minkowski}{{7}{3}{Minkowski Line Element (Einstein.4D analogy)}{equation.1.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Variational free energy functional for discrete binary states (Eq. \ref  {eq:supp_free_energy})}. This curve illustrates the free energy landscape \(\symcal {F} = -\qopname  \relax o{log}P(o|s) + \text  {KL}[Q(s)||P(s)]\) as a function of the variational distribution parameter. \textbf  {X-axis}: Variational parameter controlling the distribution over the two discrete states. \textbf  {Y-axis}: Free energy value in natural units. \textbf  {Curve shape}: The free energy exhibits a clear minimum at the optimal variational distribution, representing the best approximation to the true posterior given the constraints of the variational family. \textbf  {KL divergence component}: The free energy balances data fit (first term) with regularization (KL divergence from prior), preventing overfitting while maintaining good predictive performance. \textbf  {Optimization interpretation}: Minimizing this free energy corresponds to finding the best variational approximation to the true posterior, a fundamental task in Bayesian inference and active inference. The smooth, convex shape of the free energy landscape makes optimization straightforward using standard methods like gradient descent or natural gradient descent. This variational framework provides a principled approach to approximate inference in complex models where exact posterior computation is intractable.}}{4}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Enhanced Figure 13: 4D Natural Gradient Trajectory with Active Inference Context}. This comprehensive visualization demonstrates natural gradient descent (Eq. \ref  {eq:supp_natgrad}) operating within the Active Inference framework, showing how information-geometric optimization drives perception-action dynamics. The figure integrates the three 4D frameworks: Coxeter.4D (Euclidean) for exact measurements, Einstein.4D (Minkowski analogy) for information-geometric flows, and Fuller.4D (Synergetics) for the tetrahedral structure of the four-fold partition. The natural gradient implements geodesic motion on the information manifold, analogous to how particles follow geodesics in Einstein.4D spacetime.}}{5}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Enhanced Figure 14: Free Energy Landscape with 4D Active Inference Context}. This comprehensive visualization explores the variational free energy landscape \(\symcal {F} = -\qopname  \relax o{log}P(o|s) + \text  {KL}[Q(s)||P(s)]\) (see Eq. \ref  {eq:supp_free_energy}) within the 4D Active Inference framework. The figure demonstrates how the Free Energy Principle operates within the 4D framework: Coxeter.4D provides exact Euclidean geometry for measurements, Einstein.4D supplies information-geometric flows for optimization, and Fuller.4D offers the tetrahedral structure for representing the four-fold partition of Active Inference. The landscape shows how minimizing free energy balances prediction error with model complexity, driving both perception and action through natural gradient descent on the information manifold.}}{6}{figure.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Discrete IVM descent optimization path (final converged state)}. This static frame shows the final position of a discrete variational descent algorithm operating on the integer Quadray lattice. \textbf  {Points}: Colored spheres representing the final optimization state, each positioned at integer Quadray coordinates projected to 3D space via the default embedding matrix. \textbf  {Colors}: Each point has a distinct color for easy identification of different optimization components. \textbf  {Optimization context}: These points represent the final state of the discrete IVM descent algorithm after converging to a local optimum on the integer lattice. The tight clustering of points indicates successful convergence, with the algorithm having found a stable configuration. \textbf  {Lattice constraints}: All point positions correspond to integer Quadray coordinates, demonstrating the discrete nature of the optimization. The final configuration represents a stable ``energy level'' where further discrete moves do not improve the objective function. This visualization complements the time-series trajectory data and demonstrates the effectiveness of discrete optimization on the integer Quadray lattice.}}{7}{figure.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Bridging (CM+S3) vs Native (Ace) IVM tetravolumes across canonical integer-quadray examples}. Bars compare \(V_{ivm}\) computed via Cayley--Menger on XYZ edge lengths with \(S3=\sqrt  {9/8}\) conversion versus Tom Ace's 5×5 determinant formula operating directly on Quadray coordinates. \textbf  {Test cases}: Regular tetrahedron (V=1), unit cube decomposition (V=3), octahedron (V=4), rhombic dodecahedron (V=6), and cuboctahedron/vector equilibrium (V=20), all using integer Quadray coordinates and common edge lengths. \textbf  {Results}: The overlapping bars demonstrate numerical agreement at machine precision between the length-based Coxeter.4D approach (Cayley--Menger + S3 conversion) and the coordinate-based Fuller.4D approach (Ace 5×5), confirming the mathematical equivalence of these formulations under synergetics unit conventions. \textbf  {Methodological significance}: This validation demonstrates that the bridging approach (converting from Euclidean to IVM units) produces identical results to the native IVM approach, supporting the use of both methods interchangeably depending on whether one has access to edge lengths or direct coordinates. Raw numerical data saved as \lstinline !bridging\_vs\_native.csv! for reproducibility and further analysis.}}{8}{figure.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}High-Precision Arithmetic Note}{9}{subsection.1.8}\protected@file@percent }
\newlabel{high-precision-arithmetic-note}{{1.8}{9}{High-Precision Arithmetic Note}{subsection.1.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.8.1}Reproducibility artifacts and external validation}{9}{subsubsection.1.8.1}\protected@file@percent }
\newlabel{reproducibility-artifacts-and-external-validation}{{1.8.1}{9}{Reproducibility artifacts and external validation}{subsubsection.1.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9}Namespaces summary (notation)}{9}{subsection.1.9}\protected@file@percent }
\newlabel{namespaces-summary-notation}{{1.9}{9}{Namespaces summary (notation)}{subsection.1.9}{}}
\gdef \@abspage@last{9}
