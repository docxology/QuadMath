\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Optimization in 4D}{1}{section.1}\protected@file@percent }
\newlabel{optimization-in-4d}{{1}{1}{Optimization in 4D}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Overview}{1}{subsection.1.1}\protected@file@percent }
\newlabel{overview}{{1.1}{1}{Overview}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Nelder--Mead on Integer Lattice}{1}{subsection.1.2}\protected@file@percent }
\newlabel{neldermead-on-integer-lattice}{{1.2}{1}{Nelder--Mead on Integer Lattice}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Parameters}{1}{subsubsection.1.2.1}\protected@file@percent }
\newlabel{parameters}{{1.2.1}{1}{Parameters}{subsubsection.1.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Volume-Level Dynamics}{2}{subsection.1.3}\protected@file@percent }
\newlabel{volume-level-dynamics}{{1.3}{2}{Volume-Level Dynamics}{subsection.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Pseudocode (Sketch)}{2}{subsection.1.4}\protected@file@percent }
\newlabel{pseudocode-sketch}{{1.4}{2}{Pseudocode (Sketch)}{subsection.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Figures}{2}{subsubsection.1.4.1}\protected@file@percent }
\newlabel{figures}{{1.4.1}{2}{Figures}{subsubsection.1.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Discrete Lattice Descent (Information-Theoretic Variant)}{2}{subsection.1.5}\protected@file@percent }
\newlabel{discrete-lattice-descent-information-theoretic-variant}{{1.5}{2}{Discrete Lattice Descent (Information-Theoretic Variant)}{subsection.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Convergence and Robustness}{2}{subsection.1.6}\protected@file@percent }
\newlabel{convergence-and-robustness}{{1.6}{2}{Convergence and Robustness}{subsection.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Discrete Nelder--Mead optimization trajectory on the integer Quadray lattice}. This time-series plot tracks key diagnostic quantities across 12 optimization iterations for a simple quadratic objective function defined on the integer Quadray lattice. \textbf  {X-axis}: Optimization iteration (0 through 12). \textbf  {Y-axis}: Key diagnostic values including objective function value (blue line), simplex volume (orange line), and maximum vertex spread (green line). \textbf  {Key observations}: The objective function decreases monotonically from iteration 0 to 12, showing convergence. The simplex volume (orange) exhibits discrete plateaus characteristic of integer-lattice optimization, where the Nelder--Mead algorithm can only move to integer coordinate positions. The maximum vertex spread (green) decreases as the simplex contracts around the optimum, indicating that the four vertices of the optimization tetrahedron are converging to a tight cluster. \textbf  {Discrete lattice behavior}: Unlike continuous optimization where the simplex can shrink to arbitrary precision, the integer Quadray lattice constrains the simplex to discrete volume levels, creating the characteristic step-like volume profile. This discrete behavior is captured in the MP4 animation (\lstinline !simplex\_animation.mp4!) and the diagnostic traces in the following figure. The final simplex volume is minimal on the integer lattice, representing a stable ``energy level'' where further discrete moves do not improve the objective function.}}{3}{figure.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Tetrahedron volume scaling relationships: Euclidean vs IVM unit conventions}. This plot demonstrates the mathematical relationship between edge length scaling and tetravolume under both Euclidean (XYZ) and IVM (synergetics) unit conventions. \textbf  {X-axis}: Edge length scaling factor (0.5 to 2.0). \textbf  {Y-axis}: Tetrahedron volume in respective units. \textbf  {Blue line (Euclidean)}: Volume scales as the cube of edge length, following the standard \(V = \frac  {\sqrt  {2}}{12} \cdot L^3\) relationship for regular tetrahedra. \textbf  {Orange line (IVM)}: Volume scales as the cube of edge length but in IVM tetra-units, following \(V_{ivm} = \frac  {1}{8} \cdot L^3\) where the regular tetrahedron with unit edge has volume 1/8. \textbf  {Key insight}: The ratio between these two scaling laws is the synergetics factor \(S3 = \sqrt  {9/8} \approx 1.06066\), which converts between Euclidean and IVM volume conventions. \textbf  {Discrete optimization context}: When working on the integer Quadray lattice, this scaling relationship helps diagnose whether volume changes are due to geometric scaling or discrete lattice effects. The plot shows that both conventions preserve the cubic scaling relationship, but with different fundamental units reflecting the different geometric assumptions of Coxeter.4D (Euclidean) versus Fuller.4D (synergetics) frameworks.}}{4}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Nelder-Mead simplex evolution on integer Quadray lattice (2×2 panel)}. This comprehensive visualization shows the simplex optimization process at key iterations (0, 3, 6, 9) to demonstrate the discrete convergence behavior. \textbf  {Top-left (Iteration 0)}: Initial simplex configuration with four vertices forming a tetrahedron in 3D embedding space, starting from widely dispersed positions. \textbf  {Top-right (Iteration 3)}: Early optimization state showing initial simplex contraction and vertex repositioning toward the optimal region. \textbf  {Bottom-left (Iteration 6)}: Mid-optimization with vertices converging toward the optimum at coordinates (2,2,2). \textbf  {Bottom-right (Iteration 9)}: Final converged state where all vertices have collapsed to the optimal point (2,2,2), representing successful convergence to the global minimum. \textbf  {Key features}: Each subplot shows the tetrahedral simplex with vertices as red spheres and edges as blue lines connecting the vertices. The objective function values and vertex spread are displayed in each subplot title, showing the monotonic decrease in both quantities. \textbf  {Discrete lattice behavior}: The step-wise convergence demonstrates how the integer Quadray lattice constrains optimization to discrete volume levels, creating the characteristic plateau behavior seen in the diagnostic traces.}}{5}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Complete simplex optimization trace visualization}. This 3D plot shows the complete trajectory of all four simplex vertices across all optimization iterations, providing a comprehensive view of the optimization path. \textbf  {Vertex traces}: Each vertex follows a distinct colored path (red, blue, green, orange) from its initial position to the final converged point at (2,2,2). \textbf  {Key iteration markers}: Large markers at iterations 0, 3, 6, and 9 highlight critical stages in the optimization process. \textbf  {Convergence point}: The black star at (2,2,2) marks the final converged state where all vertices meet at the global optimum. \textbf  {Optimization insights}: The trace reveals how the simplex contracts systematically, with vertices moving in coordinated patterns that respect the integer lattice constraints. The discrete nature of the optimization is evident in the step-wise vertex movements, which can only occur to valid integer Quadray coordinates. This visualization complements the 2×2 panel view by showing the complete optimization trajectory in a single, interpretable plot.}}{6}{figure.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Information-Geometric View (Einstein.4D analogy in metric form)}{7}{subsection.1.7}\protected@file@percent }
\newlabel{information-geometric-view-einstein.4d-analogy-in-metric-form}{{1.7}{7}{Information-Geometric View (Einstein.4D analogy in metric form)}{subsection.1.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Enhanced Fisher Information Matrix (FIM) with 4D Framework Context}. This two-panel visualization shows the empirical Fisher information matrix alongside a comprehensive explanation of how it connects the three 4D frameworks. \textbf  {Left panel}: The 3×3 Fisher information matrix \(F_{ij}\) estimated from per-sample gradients of a misspecified linear regression model, displayed as a heatmap with value annotations. \textbf  {Matrix structure}: The FIM captures the local curvature of the log-likelihood surface around the current parameter estimate, with brighter colors indicating higher information content. \textbf  {Right panel}: 4D framework context explaining how the FIM bridges different mathematical frameworks. \textbf  {Coxeter.4D (Euclidean)}: Standard 3D parameter space with Euclidean metric. \textbf  {Einstein.4D (Minkowski)}: Fisher metric replaces spacetime metric; geodesics follow \(F^{-1}\nabla L\) for optimal parameter updates. \textbf  {Fuller.4D (Synergetics)}: Tetrahedral coordinate system with IVM quantization. \textbf  {Mathematical foundation}: \(F_{ij} = \frac  {1}{N}\sum _n \frac  {\partial L}{\partial w_i} \frac  {\partial L}{\partial w_j}\) where gradients are computed with respect to parameters \(w_0, w_1, w_2\). The diagonal dominance shows each parameter contributes independently to the model's predictive power, while off-diagonal elements reveal parameter interactions and potential redundancy. This FIM structure guides natural gradient descent by weighting parameter updates according to local curvature, leading to more efficient convergence than standard gradient descent.}}{7}{figure.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Multi-Objective and Higher-Dimensional Notes (Coxeter.4D perspective)}{7}{subsection.1.8}\protected@file@percent }
\newlabel{multi-objective-and-higher-dimensional-notes-coxeter.4d-perspective}{{1.8}{7}{Multi-Objective and Higher-Dimensional Notes (Coxeter.4D perspective)}{subsection.1.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Comprehensive Fisher Information Eigenspectrum with Curvature Analysis}. This enhanced two-panel visualization provides both the eigenvalue decomposition and a detailed interpretation of the parameter space geometry. \textbf  {Left panel}: Bar chart showing the eigenvalue decomposition of the empirical Fisher information matrix, with eigenvalues sorted in descending order. Each bar is color-coded and annotated with its numerical value. \textbf  {Right panel}: Curvature analysis summary providing key metrics and interpretation. \textbf  {Key metrics}: Condition number (anisotropy measure), anisotropy index (normalized directional variation), and total curvature (trace of F). \textbf  {Interpretation}: Large eigenvalues indicate directions of high curvature (tight constraints) where the objective function changes rapidly with parameter changes. Small eigenvalues indicate directions of low curvature (loose constraints) where the objective function is relatively flat. \textbf  {4D connection}: The eigenvalues reveal the anisotropic nature of the parameter space, explaining why natural gradient descent (which scales updates by \(F^{-1}\)) converges more efficiently than standard gradient descent. The principal directions provide insight into which parameter combinations are most sensitive to data changes and which are relatively stable. This geometric understanding is crucial for designing effective optimization strategies and understanding model behavior in the context of information geometry.}}{8}{figure.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Natural Gradient Trajectory: Geodesic Motion on Information Manifold}. This enhanced visualization shows the parameter trajectory of natural gradient descent with improved styling and geometric interpretation. \textbf  {Trajectory}: The blue line with markers traces the parameter evolution from initial guess to final optimum, showing the path taken through the 2D parameter space. \textbf  {Markers}: Each marker represents one optimization step, with spacing indicating the step size and convergence rate. \textbf  {Start/End markers}: Green circle marks the initial parameter values, red circle marks the converged optimum. \textbf  {4D Framework Connection}: This trajectory demonstrates geodesic motion on the information manifold, where the Fisher metric (Einstein.4D analogy) replaces the physical metric. The natural gradient follows \(F^{-1}\nabla L\), creating optimal paths through parameter space that respect the intrinsic geometry. \textbf  {Convergence behavior}: The trajectory shows smooth, direct convergence to the optimum, characteristic of natural gradient descent on well-conditioned objectives. \textbf  {Comparison with standard gradient descent}: Natural gradient descent typically produces more direct trajectories than standard gradient descent, especially on ill-conditioned problems where the parameter space has strong anisotropy. This efficiency comes from the FIM-based scaling that adapts step sizes to local curvature. The trajectory demonstrates how information-geometric optimization leverages the intrinsic geometry of the parameter space to achieve faster, more stable convergence than naive gradient methods. \textbf  {Grid overlay}: Added for better readability and to emphasize the discrete nature of the optimization steps.}}{9}{figure.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Enhanced Variational Free Energy Landscape with 4D Framework Integration}. This improved visualization shows the variational free energy \(\symcal {F} = -\qopname  \relax o{log}P(o|s) + \text  {KL}[Q(s)||P(s)]\) (see Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:supp_free_energy}\unskip \@@italiccorr )}}) as a function of the variational distribution parameter, with enhanced styling and geometric interpretation. \textbf  {X-axis}: Variational parameter \(q(\text  {state}=0)\) controlling the distribution over the two discrete states. \textbf  {Y-axis}: Free energy value \(\symcal {F}\) in natural units. \textbf  {Curve styling}: Enhanced line plot with improved thickness, color scheme, and grid overlay for better readability. \textbf  {Minimum marker}: Red circle highlights the optimal variational distribution where free energy is minimized. \textbf  {4D Framework Connection}: The free energy landscape represents the geometry of the variational manifold, where optimization follows geodesics defined by the Fisher metric (Einstein.4D analogy). In active inference frameworks, minimizing free energy drives both perception and action, analogous to how geodesics minimize proper time in relativistic spacetime. \textbf  {Curve interpretation}: The free energy exhibits a clear minimum at the optimal variational distribution, representing the best approximation to the true posterior given the constraints of the variational family. \textbf  {KL divergence component}: The free energy balances data fit (first term) with regularization (KL divergence from prior), preventing overfitting while maintaining good predictive performance. \textbf  {Optimization geometry}: The smooth, convex shape of the free energy landscape makes optimization straightforward using natural gradient descent, which respects the intrinsic geometry of the parameter space. This variational framework provides a principled approach to approximate inference in complex models where exact posterior computation is intractable, while maintaining connections to the broader 4D mathematical frameworks.}}{10}{figure.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {Figure 13: 4D Natural Gradient Trajectory with Active Inference Context}. This comprehensive visualization demonstrates natural gradient descent (Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:supp_natgrad}\unskip \@@italiccorr )}}) operating within the Active Inference framework, showing how information-geometric optimization drives perception-action dynamics. \textbf  {3D Trajectory}: The main panel shows the 4D parameter evolution in 3D space with time encoded as color, representing the four-fold partition of Active Inference: perception (μ), action (a), internal states (s), and external causes (ψ). \textbf  {Free Energy Evolution}: The right panel tracks free energy minimization over optimization steps, demonstrating the Active Inference principle of surprise reduction. \textbf  {Component Dynamics}: The bottom-left panel shows how each component of the four-fold partition evolves during optimization, revealing the coordinated dynamics of perception and action. \textbf  {4D Framework Integration}: The bottom-center panel explains how Coxeter.4D (Euclidean), Einstein.4D (Minkowski analogy), and Fuller.4D (Synergetics) frameworks integrate in this context. \textbf  {Fisher Information}: The bottom-right panel displays the Fisher Information Matrix that guides natural gradient descent, showing the information geometry underlying the optimization process. This figure demonstrates how natural gradient descent implements geodesic motion on the information manifold, analogous to how particles follow geodesics in Einstein.4D spacetime, while operating within the tetrahedral structure of Fuller.4D coordinates.}}{11}{figure.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textbf  {Figure 14: Enhanced Free Energy Landscape with 4D Active Inference Context}. This comprehensive visualization explores the variational free energy landscape \(\symcal {F} = -\qopname  \relax o{log}P(o|s) + \text  {KL}[Q(s)||P(s)]\) (see Eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:supp_free_energy}\unskip \@@italiccorr )}}) within the 4D Active Inference framework. \textbf  {3D Landscape}: The main panel shows the free energy surface over a 2D parameter space representing perception-action balance, with the global minimum marked for optimal inference. \textbf  {Contour Analysis}: The top-right panel provides 2D contours of the free energy landscape, revealing the information geometry structure that guides optimization. \textbf  {Cross-Sections}: The bottom-left panel shows free energy cross-sections at different parameter values, demonstrating parameter sensitivity and the smoothness of the optimization landscape. \textbf  {Four-Fold Partition}: The bottom-center panel illustrates the Active Inference tetrahedral structure connecting internal states (μ), sensory observations (s), actions (a), and external causes (ψ), showing how Fuller.4D geometry naturally encodes this partition. \textbf  {Local Curvature}: The bottom-right panel displays local curvature information derived from the Fisher Information structure, revealing how the information geometry adapts to different regions of the parameter space. This figure demonstrates how the Free Energy Principle operates within the 4D framework: Coxeter.4D provides exact Euclidean geometry for measurements, Einstein.4D supplies information-geometric flows for optimization, and Fuller.4D offers the tetrahedral structure for representing the four-fold partition of Active Inference. The landscape shows how minimizing free energy balances prediction error with model complexity, driving both perception and action through natural gradient descent on the information manifold.}}{12}{figure.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9}External validation and computational context}{13}{subsection.1.9}\protected@file@percent }
\newlabel{external-validation-and-computational-context}{{1.9}{13}{External validation and computational context}{subsection.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.10}Results}{13}{subsection.1.10}\protected@file@percent }
\newlabel{results}{{1.10}{13}{Results}{subsection.1.10}{}}
\gdef \@abspage@last{13}
